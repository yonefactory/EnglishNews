import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import config
import requests
from bs4 import BeautifulSoup

CNN_URL = "https://edition.cnn.com/world"

def get_top_cnn_news():
    """CNN êµ­ì œ ë‰´ìŠ¤ í™ˆí˜ì´ì§€ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê¸°ì‚¬ë¥¼ ê°€ì ¸ì˜¨ë‹¤."""
    try:
        response = requests.get(CNN_URL, headers={"User-Agent": "Mozilla/5.0"})
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"ğŸš¨ CNN ë‰´ìŠ¤ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

    soup = BeautifulSoup(response.text, "html.parser")

    # ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ ì°¾ê¸°
    top_article = soup.find("a", class_="container__link")
    if not top_article or not top_article.get("href"):
        print("ğŸš¨ CNN ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    title = top_article.text.strip()
    link = "https://edition.cnn.com" + top_article["href"]

    # ê¸°ì‚¬ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°
    try:
        article_response = requests.get(link, headers={"User-Agent": "Mozilla/5.0"})
        article_response.raise_for_status()
    except requests.RequestException:
        print("ğŸš¨ CNN ë‰´ìŠ¤ ë³¸ë¬¸ ìš”ì²­ ì‹¤íŒ¨")
        return None

    article_soup = BeautifulSoup(article_response.text, "html.parser")
    paragraphs = article_soup.find_all("p")

    content = " ".join([p.text.strip() for p in paragraphs[:5]]) if paragraphs else None

    if not content:
        print("ğŸš¨ CNN ë‰´ìŠ¤ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    return {"title": title, "content": content, "url": link}

if __name__ == "__main__":
    news = get_top_cnn_news()
    if news:
        print(f"Title: {news['title']}\nContent: {news['content']}\nURL: {news['url']}")
